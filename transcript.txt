good morning everyone david shapiro here i um i wanted to make a video about fine tuning with gpt3 um at present my most popular video is about fine-tuning gpt3 for a specific task but i wrote a post on the open ai community about just some tips and observations that i had about fine-tuning both from my own experiments but from helping other people so for instance i've been approached by lots of people startups and students wanting to get help with fine tuning and uh you know so hey i can just help everyone so let me give you five tips and misconceptions about fine-tuning gpt3 my first tip is start with normal gpt3 and prompt engineering get good with gpt3 before you jump into fine tuning gpt3 is not like any other tool you've ever used nlp or otherwise it's not like an svm it's not like a regression model it's not even like other neural networks for instance a lot of people jump in thinking assuming that they need fine tuning when they haven't even used gpt3 before and i say jump in give it a test drive it's way more powerful than you think it is and so some people just they have their their old school data science mindset like oh i need i need uh you know a data set i need to you know come up with rules and i'm like just ask it there was one case where um a recent case where someone was trying to scrape dates from unstructured task text and i'm like just ask for the dates you don't need to fine tune anything um pardon me i'm a little bit parched so be drinking my tea while i talk it's still too hot ow um yeah so jump into gpt3 plain vanilla gpt3 is way more powerful than you think it is um it knows a lot more uh it's it's read you know many gigabytes or terabytes of text i don't even know how much data it was trained on i've seen different numbers it depends on who you ask um so it's not like anything else when you when you fine tune gpt3 that's actually transfer learning uh which means you're getting the benefit of most of the learning that it's already got so it doesn't work the way that you think it does unless you've read the papers and played with it um let's see oh another thing this is one of this is a really big misconception is um prompt engineering means you have to be really good at language uh and it's really interesting my partner and i my partner is a getting her master's degree in information science so she bridges the gap between humanities and computer science so if you work with philosophers with writers with digital humanities folks they get it really fast why because they understand language they understand rhetoric they understand using the written word to communicate ideas however you put gpt3 in front of a die hard math first computer science major and they often can't see the language for the math another way of saying that is they they see the algorithm first without seeing the implication of the language and it's really interesting to see that like some people put the language first and some people put the math first so with gpt 3 you don't have to worry about the math so if you came up from you know a hardcore you know computer science algorithmic thinking um that honestly won't help you with using gpt3 and uh so some people ask me like okay well what what what what sorry stuttering um if you've watched some of my other videos you know that i stutter sometimes i don't even identify as a stutterer it just happens sometimes everyone stutters anyways sorry um but i lost my train of thought oh yeah team composition if you want to have a dynamite team using large language models make sure that you've got someone who understands language on your team maybe hire a librarian an english major a philosopher i was working with one startup for a while where they were they all had they all had humanities training they understood philosophy they understood all sorts of other psychology um psychologists get it really well too um and they all they understood it i showed them what gpt3 could do and they're like this is amazing and and i see what you mean like this is capable of philosophical reasoning um and of course you know you show a philosopher that a machine is capable of philosophical reasoning and they're blown away and you show a computer scientist and they're like yeah whatever um it's it's just this really weird dichotomy so higher humanities [Music] so that's that's all that's all within tip number one start with gpt3 plain vanilla number two tip number two building fine tuning data sets is a hundred times more effort than prompt engineering um for that reason alone start with plain vanilla gpt3 it'll carry you way farther than you think it will if you if you take gpt3 to its limits if you say okay i've worked with this tool for months and i can't get it to do what i need it to do then maybe it's time for fine tuning but even then maybe not i'll get into that in a second um but yeah like building fine tuning data sets it's super super hard um let's see now okay let's assume that you've done your homework uh you've decided yes i do need fine-tuning um my first tip is use natural language separators or demarcators to identify where the the prompt begins and the completion uh prompt ends and the completion begins sorry in the open ai documentation they just use like hashtag and while that can work it's semantically meaningless so what i usually do is i will add like just a couple words like if um in my uh in my question generating um uh fine tuning data set i have like here's you know a block of text and then i say like ask questions and then with a with a colon and gpt3 really learns okay that's where the task begins and so just like you know one one to five words giving instructions right at the end of the prompt that helps teach gpt 31 what its task actually is without having to infer what the task is because then you can be very explicit about what its task is but also that it's more semantically meaningful and the reason that semantic meaning is important is because if you if you fine-tune a data set to do multiple tasks it needs to differentiate between those tasks because like let's say let's say you're trained you're fine-tuning a chat bot right and you want to you want to train this chat bot to ask questions or provide facts or you know answer questions so ask or answer questions provide facts or just whatever you need to be able to differentiate what you want your fine tune model to do and by by using a natural language separator that means that at inference time when it's in production you can actually switch tasks without you without having to switch between different um fine-tuned models and that will save you a lot of time because let's say you make uh you know one fine-tuned data set that's got 200 samples of asking questions and 200 samples of answering questions now you've got one fine-tuned model to use and you're ready to go you're off to the races um so natural language separators that's uh that's that's a really big one that's number three number four is use gpt3 itself to make synthetic data sets i use this quite extensively gpt3 is able to simulate any kind of conversation and so you can you can either you know scrape web data which is legal there is another what was it ninth district us circuit court just said like yes using scrapes web data is perfectly legal as long as it's publicly accessible it's not hacking it's not theft if someone puts public data on the internet you're free to use it so i scrape reddit public reddit as a way of getting kind of some raw material but then what you can do is and oh check check the description i've got a public repo with all of my publicly available fine-tuning data sets so you can go see what i'm talking about um but by by synthesizing a data set one it's way easier you write a few good really good prompts to say to to generate the kind of output that you want the kind of input and output that you want and then you're off to the races it takes me you know an hour flat to make a new fine-tuning data set because it's just it's just a couple of scripts to take in some raw material and massage those into prompts which the the latest instruct models instruct series of gpt3 models are really great at generating synthetic output or synthetic data sets and then you're you're ready to go um so one thing that i need to say there though is um going back to point one fine-tuning gpt3 is not like conventional ml there was one person on the forum who thought that he needed two hundred thousand samples um to fine-tune gpt three for a good chat bot i said no you need two hundred not two hundred thousand two hundred and i i did the numbers and i was like this is like what a dollar like if you depending on the the model you use it's like 18 cents to fine-tune with 200 samples i think if you use davinci it's a dollar eighty right so curie can do most tasks so you fine-tune a curie model it'll be faster and cheaper costs 18 cents to fine-tune with 200 samples and that was like a high water mark that's if you use a thousand tokens per training sample which most of them are going to be a tenth of that because because of how aligned the models are now um so you know it takes way less data than you think to get started and i proved my point i gave i that's that that post is actually why i publicly posted my fine tuning data set i said go grab my chat bot um fine tuning data and run it yourself if you don't believe me and he went and he did he said this is impressive he said you know there's still some problems but it performs way better than i thought it would on just 200 samples um so yes and i used gpt3 to make the fine tuning set and then i went and manually cleaned it up by hand that's way faster than doing a whole data set by hand number five fine tuning tends to increase consistency at the cost of creativity sometimes that's what you need because gpt3 on its own can be really creative right gpt3 is able to adopt any mental framework you can tell it like pretend to be yosemite sam as looney tunes back in the day that's dating myself it can pretend to be bugs bunny spiderman you can talk to it about philosophy you can talk to it about racism it can take the perspective of different religions right so plain vanilla gpt3 is really creative it's more creative than any 10 humans but fine tuning because you're going to show it a bunch of data set samples from a particular perspective it'll kind of lose those other perspectives so just keep that in mind if you're trying to do a creative task prompt engineering is going to be better than fine tuning but if you if you really do need consistency and a lot of tasks do i'm not saying that this is a bad thing just something to be in keep in mind is if you want if you want your gpt3 app to be able to provide really creative answers or solutions fine tuning is going to reduce that ability whereas if you need something to be very consistent like if there's a particular format to follow that's where fine tuning really shines so yeah five tips for uh five tips and misconceptions about gpt3 and fine tuning i hope you found this helpful thanks for watching oh also like and subscribe